{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neo4j import Query, GraphDatabase, RoutingControl, Result # Python database driver 5.13 +"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_ULR = \"neo4j://localhost:7687\"\n",
    "DB_USER = \"neo4j\"\n",
    "DB_PASS = \"test1234\"\n",
    "DB_NAME = \"neo4j\" # Have to be neo4j for neo4j aura (but keep it, good for testing on local dev env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(DB_ULR, auth=(DB_USER, DB_PASS))\n",
    "driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure database (skip this step on neo4j aura)\n",
    "records, summary, keys = driver.execute_query(\n",
    "    \"create database {dbname} if not exists\".format(dbname = DB_NAME),\n",
    "    database_=\"system\",\n",
    "    routing_=RoutingControl.WRITE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utility\n",
    "def split_dataframe(df, chunk_size = 5000): \n",
    "    chunks = list()\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define indexes and constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_statements = [\n",
    "    'create constraint if not exists for (n:UseCase) require (n.name) is node key',\n",
    "    'create constraint if not exists for (n:Industry) require (n.name) is ::String'\n",
    "]\n",
    "for statement in schema_statements:\n",
    "    driver.execute_query(\n",
    "        statement,\n",
    "        database_=DB_NAME,\n",
    "        routing_=RoutingControl.WRITE\n",
    "    )\n",
    "\n",
    "# Fetch all constraints\n",
    "schema_result_df  = driver.execute_query(\n",
    "    'show constraints',\n",
    "    database_=DB_NAME,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")\n",
    "schema_result_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_df = pd.read_parquet('./syth_sdtm/dm_synth.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_df = pd.read_parquet('./syth_sdtm/sv_synth.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not wrapped in split_dataframe (looks cleaner if you only have a couple of thousand rows of data to process)\n",
    "# driver.execute_query(\n",
    "#     ''' \n",
    "#         unwind $rows as row\n",
    "#         merge (n:UseCase{name: row['COL1']})\n",
    "#             set n.description = row['COL2]\n",
    "#         return count(*) as rows_processed\n",
    "#     ''',\n",
    "#     database_=DB_NAME,\n",
    "#     routing_=RoutingControl.WRITE,\n",
    "#     rows = data[['COL1', 'COL1']].drop_duplicates().to_dict('records')\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClinicalStudy nodes\n",
    "for chunk in split_dataframe(dm_df[['STUDYID']].drop_duplicates()):\n",
    "    records, summary, keys = driver.execute_query(\n",
    "        ''' \n",
    "            unwind $rows as row\n",
    "            merge (cs:ClinicalStudy{id: row.STUDYID})\n",
    "            return count(*) as rows_processed\n",
    "        ''',\n",
    "        database_=DB_NAME,\n",
    "        routing_=RoutingControl.WRITE,\n",
    "        rows = chunk.to_dict('records')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PatientVisist nodes\n",
    "# + example for how to do resonable sized transactions in the database\n",
    "for chunk in split_dataframe(sv_df[['STUDYID', 'USUBJID','VISITNUM','SVSTDTC','VISIT']].drop_duplicates()):\n",
    "    records, summary, keys = driver.execute_query(\n",
    "        ''' \n",
    "            unwind $rows as row\n",
    "            merge (pv:PatientVisit{study_id: row.STUDYID, visit_num: row.VISITNUM, patient_id: row.USUBJID})\n",
    "            set pv.date = datetime(row.SVSTDTC),\n",
    "                pv.type = row.visist\n",
    "            return count(*) as rows_processed\n",
    "        ''',\n",
    "        database_=DB_NAME,\n",
    "        routing_=RoutingControl.WRITE,\n",
    "        rows = chunk.to_dict('records')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Person nodes\n",
    "records, summary, keys = driver.execute_query(\n",
    "    ''' \n",
    "        unwind $rows as row\n",
    "        merge (pv:Person{id: row.USUBJID})\n",
    "        return count(*) as rows_processed\n",
    "    ''',\n",
    "    database_=DB_NAME,\n",
    "    routing_=RoutingControl.WRITE,\n",
    "    rows = sv_df[['USUBJID']].drop_duplicates().to_dict('records')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (:Person)<-[:PATIENT]-(:PatientVisist) Relationships\n",
    "records, summary, keys = driver.execute_query(\n",
    "    ''' \n",
    "        unwind $rows as row\n",
    "        match (pv:PatientVisit{study_id: row.STUDYID, visit_num: row.VISITNUM, patient_id: row.USUBJID}),\n",
    "              (p:Person{id: row.USUBJID})\n",
    "        merge (p)<-[:PATIENT]-(pv)\n",
    "        return count(*) as rows_processed\n",
    "    ''',\n",
    "    database_=DB_NAME,\n",
    "    routing_=RoutingControl.WRITE,\n",
    "    rows = sv_df[['STUDYID', 'USUBJID','VISITNUM','SVSTDTC','VISIT']].drop_duplicates().to_dict('records')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (:ClinicalStudy)<-[:STUDY]-(:PatientVisist) Relationships\n",
    "records, summary, keys = driver.execute_query(\n",
    "    ''' \n",
    "        unwind $rows as row\n",
    "        match (pv:PatientVisit{study_id: row.STUDYID, visit_num: row.VISITNUM, patient_id: row.USUBJID}),\n",
    "              (s:ClinicalStudy{id: row.STUDYID})\n",
    "        merge (s)<-[:STUDY]-(pv)\n",
    "        return count(*) as rows_processed\n",
    "    ''',\n",
    "    database_=DB_NAME,\n",
    "    routing_=RoutingControl.WRITE,\n",
    "    rows = sv_df[['STUDYID', 'USUBJID','VISITNUM','SVSTDTC','VISIT']].drop_duplicates().to_dict('records')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
