{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from neo4j import Query, GraphDatabase, RoutingControl, Result # Python database driver 5.13 +"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_ULR = \"neo4j://localhost:7687\"\n",
    "DB_USER = \"neo4j\"\n",
    "DB_PASS = \"test1234\"\n",
    "DB_NAME = \"demo\" # Have to be neo4j for neo4j aura (but keep it, good for testing on local dev env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(DB_ULR, auth=(DB_USER, DB_PASS))\n",
    "driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure database (skip this step on neo4j aura)\n",
    "records, summary, keys = driver.execute_query(\n",
    "    \"create database {dbname} if not exists\".format(dbname = DB_NAME),\n",
    "    database_=\"system\",\n",
    "    routing_=RoutingControl.WRITE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utility\n",
    "def split_dataframe(df, chunk_size = 5000): \n",
    "    chunks = list()\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define indexes and constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_statements = [\n",
    "    'create constraint if not exists for (n:UseCase) require (n.name) is node key',\n",
    "    'create constraint if not exists for (n:Industry) require (n.name) is ::String',\n",
    "    'create constraint if not exists for (n:BusinessConcept) require (n.id) is node key',\n",
    "]\n",
    "for statement in schema_statements:\n",
    "    driver.execute_query(\n",
    "        statement,\n",
    "        database_=DB_NAME,\n",
    "        routing_=RoutingControl.WRITE\n",
    "    )\n",
    "\n",
    "# Fetch all constraints\n",
    "schema_result_df  = driver.execute_query(\n",
    "    'show constraints',\n",
    "    database_=DB_NAME,\n",
    "    routing_=RoutingControl.READ,\n",
    "    result_transformer_= lambda r: r.to_df()\n",
    ")\n",
    "schema_result_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_df = pd.read_parquet('./syth_sdtm/dm_synth.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_df = pd.read_parquet('./syth_sdtm/sv_synth.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not wrapped in split_dataframe (looks cleaner if you only have a couple of thousand rows of data to process)\n",
    "# driver.execute_query(\n",
    "#     ''' \n",
    "#         unwind $rows as row\n",
    "#         merge (n:UseCase{name: row['COL1']})\n",
    "#             set n.description = row['COL2]\n",
    "#         return count(*) as rows_processed\n",
    "#     ''',\n",
    "#     database_=DB_NAME,\n",
    "#     routing_=RoutingControl.WRITE,\n",
    "#     rows = data[['COL1', 'COL1']].drop_duplicates().to_dict('records')\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create business concept nodes\n",
    "for chunk in split_dataframe(dm_df[['id', 'name']].drop_duplicates()):\n",
    "    records, summary, keys = driver.execute_query(\n",
    "        ''' \n",
    "            unwind $rows as row\n",
    "            merge (bc:BusnessConecept{id: row.id})\n",
    "                set bc.term = row.name\n",
    "            return count(*) as rows_processed\n",
    "        ''',\n",
    "        database_=DB_NAME,\n",
    "        routing_=RoutingControl.WRITE,\n",
    "        rows = chunk.to_dict('records')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClinicalStudy nodes\n",
    "for chunk in split_dataframe(dm_df[['STUDYID']].drop_duplicates()):\n",
    "    records, summary, keys = driver.execute_query(\n",
    "        ''' \n",
    "            unwind $rows as row\n",
    "            merge (cs:ClinicalStudy{id: row.STUDYID})\n",
    "            return count(*) as rows_processed\n",
    "        ''',\n",
    "        database_=DB_NAME,\n",
    "        routing_=RoutingControl.WRITE,\n",
    "        rows = chunk.to_dict('records')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# PatientVisist nodes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# + example for how to do resonable sized transactions in the database\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[43msplit_dataframe\u001b[49m(sv_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTUDYID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSUBJID\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVISITNUM\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVSTDTC\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVISIT\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()):\n\u001b[1;32m      4\u001b[0m     records, summary, keys \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mexecute_query(\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124;03m''' \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m            unwind $rows as row\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m         rows \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mto_dict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'split_dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "# PatientVisist nodes\n",
    "# + example for how to do resonable sized transactions in the database\n",
    "for chunk in split_dataframe(sv_df[['STUDYID', 'USUBJID','VISITNUM','SVSTDTC','VISIT']].drop_duplicates()):\n",
    "    records, summary, keys = driver.execute_query(\n",
    "        ''' \n",
    "            unwind $rows as row\n",
    "            merge (pv:PatientVisit{study_id: row.STUDYID, visit_num: row.VISITNUM, patient_id: row.USUBJID})\n",
    "            set pv.date = datetime(row.SVSTDTC),\n",
    "                pv.type = row.visist\n",
    "            ....\n",
    "            return count(*) as rows_processed\n",
    "        ''',\n",
    "        database_=DB_NAME,\n",
    "        routing_=RoutingControl.WRITE,\n",
    "        rows = chunk.to_dict('records')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Person nodes\n",
    "records, summary, keys = driver.execute_query(\n",
    "    ''' \n",
    "        unwind $rows as row\n",
    "        merge (pv:Person{id: row.USUBJID})\n",
    "        return count(*) as rows_processed\n",
    "    ''',\n",
    "    database_=DB_NAME,\n",
    "    routing_=RoutingControl.WRITE,\n",
    "    rows = sv_df[['USUBJID']].drop_duplicates().to_dict('records')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temp\n",
    "def get_person(person_id):\n",
    "\n",
    "    records, summary, keys = driver.execute_query(\n",
    "        ''' \n",
    "            match (pv:Person{id: $person_idn})\n",
    "            return count(*) as rows_processed\n",
    "        ''',\n",
    "        database_=DB_NAME,\n",
    "        routing_=RoutingControl.READ,\n",
    "        person_id = person_id\n",
    "    )\n",
    "    return records[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (:Person)<-[:PATIENT]-(:PatientVisist) Relationships\n",
    "records, summary, keys = driver.execute_query(\n",
    "    ''' \n",
    "        unwind $rows as row\n",
    "        match (pv:PatientVisit{study_id: row.STUDYID, visit_num: row.VISITNUM, patient_id: row.USUBJID}),\n",
    "              (p:Person{id: row.USUBJID})\n",
    "        merge (p)<-[r:PATIENT]-(pv)\n",
    "        return count(*) as rows_processed\n",
    "    ''',\n",
    "    database_=DB_NAME,\n",
    "    routing_=RoutingControl.WRITE,\n",
    "    rows = sv_df[['STUDYID', 'USUBJID','VISITNUM','SVSTDTC','VISIT']].drop_duplicates().to_dict('records')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (:ClinicalStudy)<-[:STUDY]-(:PatientVisist) Relationships\n",
    "records, summary, keys = driver.execute_query(\n",
    "    ''' \n",
    "        unwind $rows as row\n",
    "        match (pv:PatientVisit{study_id: row.STUDYID, visit_num: row.VISITNUM, patient_id: row.USUBJID}),\n",
    "              (s:ClinicalStudy{id: row.STUDYID})\n",
    "        merge (s)<-[:STUDY]-(pv)\n",
    "        return count(*) as rows_processed\n",
    "    ''',\n",
    "    database_=DB_NAME,\n",
    "    routing_=RoutingControl.WRITE,\n",
    "    rows = sv_df[['STUDYID', 'USUBJID','VISITNUM','SVSTDTC','VISIT']].drop_duplicates().to_dict('records')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebooks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
