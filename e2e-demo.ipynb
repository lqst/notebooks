{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DB_ULR = \"neo4j://localhost:7687\"\n",
    "DB_USER = \"neo4j\"\n",
    "DB_PASS = \"test1234\"\n",
    "DB_NAME = \"e2edemo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create driver\n",
    "Also set the DB_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from neo4j import GraphDatabase # Python database driver\n",
    "from graphdatascience import GraphDataScience # Python GDS client\n",
    "\n",
    "# And some cermony to create the driver and gds objects\n",
    "driver = GraphDatabase.driver(DB_ULR, auth=(DB_USER, DB_PASS))\n",
    "gds = GraphDataScience(DB_ULR, auth=(DB_USER, DB_PASS))\n",
    "gds.set_database(DB_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create databse and schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Create (or replace) database\n",
    "with driver.session(database = \"system\") as session:\n",
    "    result = session.write_transaction( lambda tx: \n",
    "        tx.run(\n",
    "            \"CREATE IF NOT EXISTS DATABASE {dbname}\".format(dbname = DB_NAME)\n",
    "        ).data()\n",
    "    )\n",
    "    df = pd.DataFrame(result)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create indexes and constraints\n",
    "with driver.session(database = DB_NAME) as session:\n",
    "    session.write_transaction( lambda tx: \n",
    "        tx.run(\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (n:Visitor) REQUIRE (n.id) IS NODE KEY\"\n",
    "        ).consume()\n",
    "    )\n",
    "    session.write_transaction( lambda tx: \n",
    "        tx.run(\n",
    "            \"CREATE CONSTRAINT IF NOT EXISTS FOR (n:Item) REQUIRE (n.id) IS NODE KEY\"\n",
    "        ).consume()     \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp  visitorid event  itemid  transactionid\n",
      "0        1433221332117     257597  view  355908            NaN\n",
      "1        1433224214164     992329  view  248676            NaN\n",
      "2        1433221999827     111016  view  318965            NaN\n",
      "3        1433221955914     483717  view  253185            NaN\n",
      "4        1433221337106     951259  view  367447            NaN\n",
      "...                ...        ...   ...     ...            ...\n",
      "2756096  1438398785939     591435  view  261427            NaN\n",
      "2756097  1438399813142     762376  view  115946            NaN\n",
      "2756098  1438397820527    1251746  view   78144            NaN\n",
      "2756099  1438398530703    1184451  view  283392            NaN\n",
      "2756100  1438400163914     199536  view  152913            NaN\n",
      "\n",
      "[2756101 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read csv file\n",
    "# Source https://www.kaggle.com/retailrocket/ecommerce-dataset?select=events.csv\n",
    "csv = pd.read_csv('/Users/haklof/datasets/events.csv')\n",
    "print(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           257597\n",
      "1           992329\n",
      "2           111016\n",
      "3           483717\n",
      "4           951259\n",
      "            ...   \n",
      "2756083    1392454\n",
      "2756093     226214\n",
      "2756096     591435\n",
      "2756097     762376\n",
      "2756099    1184451\n",
      "Name: visitorid, Length: 1407580, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select all unique visitors\n",
    "visitors = csv['visitorid'].drop_duplicates().dropna()\n",
    "print(visitors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nodesCreated\n",
      "0        140758\n",
      "   nodesCreated\n",
      "0        140758\n",
      "   nodesCreated\n",
      "0        140758\n",
      "   nodesCreated\n",
      "0        140758\n",
      "   nodesCreated\n",
      "0        140758\n",
      "   nodesCreated\n",
      "0        140758\n",
      "   nodesCreated\n",
      "0        140758\n",
      "   nodesCreated\n",
      "0        140758\n",
      "   nodesCreated\n",
      "0        140758\n",
      "   nodesCreated\n",
      "0        140758\n"
     ]
    }
   ],
   "source": [
    "# Create Visitor nodes\n",
    "for chunk in np.array_split(visitors, 10):\n",
    "    with driver.session(database = DB_NAME) as session:\n",
    "        result = session.write_transaction( lambda tx: \n",
    "            tx.run(\n",
    "                \"\"\"\n",
    "                UNWIND $visitors as visitorId\n",
    "                MERGE (:Visitor{id: visitorId})\n",
    "                RETURN count(*) as nodesCreated\n",
    "                \"\"\",\n",
    "                visitors = chunk.to_list()\n",
    "            ).data()\n",
    "        )\n",
    "        df = pd.DataFrame(result)\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          355908\n",
      "1          248676\n",
      "2          318965\n",
      "3          253185\n",
      "4          367447\n",
      "            ...  \n",
      "2756002     19206\n",
      "2756039    172413\n",
      "2756042       613\n",
      "2756060     52086\n",
      "2756062    177353\n",
      "Name: itemid, Length: 235061, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select all unique Items\n",
    "items = csv['itemid'].drop_duplicates().dropna()\n",
    "print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   nodesCreated\n",
      "0        235061\n"
     ]
    }
   ],
   "source": [
    "# Create Item nodes\n",
    "with driver.session(database = DB_NAME) as session:\n",
    "    result = session.write_transaction( lambda tx: \n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            UNWIND $items as itemId\n",
    "            MERGE (:Item{id: itemId})\n",
    "            RETURN count(*) as nodesCreated\n",
    "            \"\"\",\n",
    "            items = items.to_list()\n",
    "        ).data()\n",
    "    )\n",
    "    df = pd.DataFrame(result)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         visitorid  itemid      timestamp\n",
      "0           257597  355908  1433221332117\n",
      "1           992329  248676  1433224214164\n",
      "2           111016  318965  1433221999827\n",
      "3           483717  253185  1433221955914\n",
      "4           951259  367447  1433221337106\n",
      "...            ...     ...            ...\n",
      "2756096     591435  261427  1438398785939\n",
      "2756097     762376  115946  1438399813142\n",
      "2756098    1251746   78144  1438397820527\n",
      "2756099    1184451  283392  1438398530703\n",
      "2756100     199536  152913  1438400163914\n",
      "\n",
      "[2664312 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select all VIEWD relationships\n",
    "viewed = csv[csv['event'] == 'view'][['visitorid','itemid', 'timestamp']]\n",
    "print(viewed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   relsCreated\n",
      "0       133216\n",
      "   relsCreated\n",
      "0       133216\n",
      "   relsCreated\n",
      "0       133216\n",
      "   relsCreated\n",
      "0       133216\n",
      "   relsCreated\n",
      "0       133216\n",
      "   relsCreated\n",
      "0       133216\n",
      "   relsCreated\n",
      "0       133216\n",
      "   relsCreated\n",
      "0       133216\n",
      "   relsCreated\n",
      "0       133216\n",
      "   relsCreated\n",
      "0       133216\n",
      "   relsCreated\n",
      "0       133216\n",
      "   relsCreated\n",
      "0       133216\n",
      "   relsCreated\n",
      "0       133215\n",
      "   relsCreated\n",
      "0       133215\n",
      "   relsCreated\n",
      "0       133215\n",
      "   relsCreated\n",
      "0       133215\n",
      "   relsCreated\n",
      "0       133215\n",
      "   relsCreated\n",
      "0       133215\n",
      "   relsCreated\n",
      "0       133215\n",
      "   relsCreated\n",
      "0       133215\n"
     ]
    }
   ],
   "source": [
    "# Create VIEWED relationships\n",
    "for chunk in np.array_split(viewed, 20):\n",
    "    with driver.session(database = DB_NAME) as session:\n",
    "        result = session.write_transaction( lambda tx: \n",
    "            tx.run(\n",
    "                \"\"\"\n",
    "                UNWIND $data as rel\n",
    "                MATCH (i:Item{id: rel.itemid}), (v:Visitor{id: rel.visitorid})\n",
    "                MERGE (v)-[:VIEWED{timestamp: rel.timestamp}]->(i)\n",
    "                RETURN count(*) as relsCreated\n",
    "                \"\"\",\n",
    "                data = chunk.to_dict('records')\n",
    "            ).data()\n",
    "        )\n",
    "        df = pd.DataFrame(result)\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         visitorid  itemid      timestamp\n",
      "17          287857    5206  1433223236124\n",
      "19          158090   10572  1433221078505\n",
      "63         1193904  255275  1433223543021\n",
      "112         599528  356475  1433221941632\n",
      "179         105775  312728  1433220880956\n",
      "...            ...     ...            ...\n",
      "2755956     831605   57810  1438400400805\n",
      "2756056      10670  419736  1438398156086\n",
      "2756074     144106  141241  1438400994744\n",
      "2756078     804736  447661  1438399807937\n",
      "2756090     804736  346534  1438399811281\n",
      "\n",
      "[69332 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select all ADDED relationships\n",
    "added = csv[csv['event'] == 'addtocart'][['visitorid','itemid', 'timestamp']]\n",
    "print(added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   relsCreated\n",
      "0        69332\n"
     ]
    }
   ],
   "source": [
    "# Create ADDED relationships\n",
    "with driver.session(database = DB_NAME) as session:\n",
    "    result = session.write_transaction( lambda tx: \n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            UNWIND $data as rel\n",
    "            MATCH (i:Item{id: rel.itemid}), (v:Visitor{id: rel.visitorid})\n",
    "            CREATE (v)-[:ADDED{timestamp: rel.timestamp}]->(i)\n",
    "            RETURN count(*) as relsCreated\n",
    "            \"\"\",\n",
    "            data = added.to_dict('records')\n",
    "        ).data()\n",
    "    )\n",
    "    df = pd.DataFrame(result)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         visitorid  itemid      timestamp  transactionid\n",
      "130         599528  356475  1433222276276           4000\n",
      "304         121688   15335  1433193500981          11117\n",
      "418         552148   81345  1433193915008           5444\n",
      "814         102019  150318  1433176736375          13556\n",
      "843         189384  310791  1433174518180           7244\n",
      "...            ...     ...            ...            ...\n",
      "2755294    1050575   31640  1438377176570           8354\n",
      "2755349     861299  456602  1438379878779           3643\n",
      "2755508     855941  235771  1438357730123           4385\n",
      "2755603     548772   29167  1438355560300          13872\n",
      "2755607    1051054  312728  1438358989163          17579\n",
      "\n",
      "[22457 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select all BOUGHT relationships\n",
    "bought = csv[csv['event'] == 'transaction'][['visitorid','itemid', 'timestamp', 'transactionid']]\n",
    "bought.transactionid = bought.transactionid.astype(int)\n",
    "print(bought)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   relsCreated\n",
      "0        22457\n"
     ]
    }
   ],
   "source": [
    "# Create BOUGHT relationships\n",
    "with driver.session(database = DB_NAME) as session:\n",
    "    result = session.write_transaction( lambda tx: \n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            UNWIND $data as rel\n",
    "            MATCH (i:Item{id: rel.itemid}), (v:Visitor{id: rel.visitorid})\n",
    "            CREATE (v)-[:BOUGHT{timestamp: rel.timestamp, transactionid: rel.transactionid}]->(i)\n",
    "            RETURN count(*) as relsCreated\n",
    "            \"\"\",\n",
    "            data = bought.to_dict('records')\n",
    "        ).data()\n",
    "    )\n",
    "    df = pd.DataFrame(result)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some basic queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   itemid  times_bought  times_added  times_viewed\n",
      "0  461686           133          306          2538\n",
      "1  119736            97           44           752\n",
      "2  213834            92           17           293\n",
      "3    7943            46           97          1346\n",
      "4  312728            46          162           947\n",
      "5  445351            45           89           939\n",
      "6   48030            41           95           986\n",
      "7  248455            38           52           575\n",
      "8  420960            38           60           795\n",
      "9   17478            37           72           631\n"
     ]
    }
   ],
   "source": [
    "# Top sellers\n",
    "with driver.session(database = DB_NAME) as session:\n",
    "    result = session.read_transaction( lambda tx: \n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            MATCH (i:Item)<-[:BOUGHT]-()\n",
    "            RETURN  i.id as itemid, \n",
    "                    count(*) as times_bought,\n",
    "                    size( (i:Item)<-[:ADDED]-() ) as times_added,\n",
    "                    size( (i:Item)<-[:VIEWED]-() ) as times_viewed\n",
    "            ORDER BY times_bought desc limit $limit\n",
    "            \"\"\",\n",
    "            limit = 10\n",
    "        ).data()\n",
    "    )\n",
    "    df = pd.DataFrame(result)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_bought  times_bought\n",
      "0          119736            59\n",
      "1          213834            18\n",
      "2          171878            13\n",
      "3          248455            12\n",
      "4           10572            11\n",
      "5          218794            10\n",
      "6          369158            10\n",
      "7             546             9\n",
      "8           32581             8\n",
      "9          320130             8\n"
     ]
    }
   ],
   "source": [
    "# Collaberative filtering\n",
    "# Suggest what other Items Visitors buy for a Visitor veiwing an Item (where the Visitor has not added/bought the Item already)\n",
    "with driver.session(database = DB_NAME) as session:\n",
    "    result = session.read_transaction( lambda tx: \n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            MATCH (i:Item{id: $itemid})<-[:VIEWED]-(visitor)-[bought:BOUGHT]->(otherItem)\n",
    "            WHERE i <> otherItem\n",
    "            AND NOT (:Visitor{id: $visitorid})-[:BOUGHT|ADDED]->(otherItem)\n",
    "            RETURN  otherItem.id as product_bought, \n",
    "                    count(distinct bought) as times_bought\n",
    "            ORDER BY times_bought desc limit $limit\n",
    "            \"\"\",\n",
    "            limit = 10, itemid = 461686, visitorid=684514\n",
    "        ).data()\n",
    "    )\n",
    "    df = pd.DataFrame(result)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_bought  times_bought_together\n",
      "0          171878                      9\n",
      "1          218794                      8\n",
      "2           32581                      8\n",
      "3           10572                      8\n",
      "4          124081                      4\n",
      "5          447067                      3\n",
      "6           75392                      3\n",
      "7          108924                      3\n",
      "8           40630                      2\n",
      "9          192043                      2\n"
     ]
    }
   ],
   "source": [
    "# Collaberative filtering (alternative)\n",
    "# Suggest based on what other items that were checked out in same transaction\n",
    "with driver.session(database = DB_NAME) as session:\n",
    "    result = session.read_transaction( lambda tx: \n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            MATCH (i:Item{id: $itemid})<-[b1:BOUGHT]-(visitor)-[b2:BOUGHT]->(otherItem)\n",
    "            WHERE i <> otherItem\n",
    "            AND b1.transactionid = b2.transactionid\n",
    "            AND NOT (:Visitor{id: $visitorid})-[:BOUGHT|ADDED]->(otherItem)\n",
    "            RETURN  otherItem.id as product_bought, \n",
    "                    count(distinct b1.transactionid) as times_bought_together\n",
    "            ORDER BY times_bought_together desc limit $limit\n",
    "            \"\"\",\n",
    "            limit = 10, itemid = 461686, visitorid=684514\n",
    "        ).data()\n",
    "    )\n",
    "    df = pd.DataFrame(result)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions so far?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph data science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    max  p0.999  p0.99  p0.90  p0.75  min\n",
      "0  7757    47.0   13.0    3.0    2.0    1\n"
     ]
    }
   ],
   "source": [
    "# Do we have any \"abnormal visitors\"\n",
    "with driver.session(database = DB_NAME) as session:\n",
    "    result = session.read_transaction( lambda tx: \n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            MATCH (v:Visitor)-[:VIEWED|ADDED|BOUGHT]->()\n",
    "            WITH v, \n",
    "                 count(*) as number_of_events\n",
    "            RETURN  max(number_of_events) as `max`,\n",
    "                    percentileCont(number_of_events, 0.999) as `p0.999`,\n",
    "                    percentileCont(number_of_events, 0.99) as `p0.99`,\n",
    "                    percentileCont(number_of_events, 0.9) as `p0.90`,\n",
    "                    percentileCont(number_of_events, 0.75) as `p0.75`,\n",
    "                    min(number_of_events) as `min`\n",
    "            \"\"\",\n",
    "            limit = 10\n",
    "        ).data()\n",
    "    )\n",
    "    df = pd.DataFrame(result)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   number_of_abnormal_visitors\n",
      "0                         1225\n"
     ]
    }
   ],
   "source": [
    "# Re-label abnormal visitors\n",
    "with driver.session(database = DB_NAME) as session:\n",
    "    result = session.write_transaction( lambda tx: \n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            MATCH (v:Visitor)-[:VIEWED|ADDED|BOUGHT]->()\n",
    "            WITH v, \n",
    "                 count(*) as number_of_events\n",
    "            WHERE number_of_events > 50\n",
    "            SET v:AbnormalVisitor\n",
    "            REMOVE v:Visitor\n",
    "            RETURN count(*) as number_of_abnormal_visitors\n",
    "            \"\"\",\n",
    "            limit = 10\n",
    "        ).data()\n",
    "    )\n",
    "    df = pd.DataFrame(result)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to do it from the neo4j browser / cypher shell\n",
    "```cypher\n",
    "call gds.graph.create.cypher(\n",
    "    'items',\n",
    "    'MATCH (i:Item) return id(i) as id',\n",
    "    'MATCH (i1:Item)<-[r1:VIEWED]-(v:Visitor)-[r2:VIEWED|ADDED|BOUGHT]->(i2:Item)\n",
    "     WHERE r1.timestamp<r2.timestamp\n",
    "     WITH i1, i2, r1, case type(r2) when \"BOUGHT\" then 1.0 when \"ADDED\" then 0.7 else 0.2 end as weight\n",
    "     RETURN id(i1) as target, id(i2) as source, weight',\n",
    "     {readConcurrency:16}\n",
    ")\n",
    "\n",
    "call gds.pageRank.stats('items', {maxIterations:200, relationshipWeightProperty:'weight', concurrency:16})\n",
    "\n",
    "call gds.pageRank.write('items', {maxIterations:200, relationshipWeightProperty:'weight', concurrency:16, writeProperty:'pagerank'})\n",
    "\n",
    "call gds.graph.drop('items')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to do it with the GraphDataScience python wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = gds.graph.create.cypher(\n",
    "    'items',\n",
    "    \"\"\"\n",
    "    MATCH (i:Item) return id(i) as id\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "        MATCH (i1:Item)<-[r1:VIEWED]-(v:Visitor)-[r2:VIEWED|ADDED|BOUGHT]->(i2:Item)\n",
    "        WHERE r1.timestamp<r2.timestamp\n",
    "        WITH i1, i2, r1, case type(r2) when \"BOUGHT\" then 1.0 when \"ADDED\" then 0.7 else 0.2 end as weight\n",
    "        RETURN id(i1) as target, id(i2) as source, weight\n",
    "     \"\"\",\n",
    "    readConcurrency=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 235,061 Rels: 5,018,193 \n"
     ]
    }
   ],
   "source": [
    "print( \"Nodes: {nodes:,} Rels: {rels:,} \".format(nodes = G.node_count(), rels=G.relationship_count()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerankRes = gds.pageRank.write(G, maxIterations=200, relationshipWeightProperty='weight', concurrency=16, writeProperty='pagerank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'writeMillis': 392, 'nodePropertiesWritten': 235061, 'ranIterations': 121, 'didConverge': True, 'centralityDistribution': {'p99': 5.043791770935059, 'min': 0.14999961853027344, 'max': 110.65331935882568, 'mean': 0.5944112732294387, 'p90': 1.292281150817871, 'p50': 0.21144485473632812, 'p999': 13.032469749450684, 'p95': 2.079451560974121, 'p75': 0.6121091842651367}, 'postProcessingMillis': 83, 'preProcessingMillis': 0, 'computeMillis': 10164, 'configuration': {'maxIterations': 200, 'writeConcurrency': 16, 'relationshipWeightProperty': 'weight', 'concurrency': 16, 'sourceNodes': [], 'writeProperty': 'pagerank', 'scaler': 'NONE', 'nodeLabels': ['*'], 'sudo': False, 'dampingFactor': 0.85, 'relationshipTypes': ['*'], 'tolerance': 1e-07, 'username': None}}\n"
     ]
    }
   ],
   "source": [
    "print(pagerankRes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_bought       rank  times_bought\n",
      "0          257040  66.998162             4\n",
      "1          309778  65.395879             2\n",
      "2            9877  45.231441             8\n",
      "3          320130  41.140090             8\n",
      "4          445351  38.658325             6\n",
      "5          409804  38.333878             4\n",
      "6           29196  37.918723             2\n",
      "7           37029  36.671724             7\n",
      "8          369447  35.673712             1\n",
      "9          234255  35.013012             6\n"
     ]
    }
   ],
   "source": [
    "# Can we suggest an Item with high probability of conversion (central to conversion)\n",
    "with driver.session(database = DB_NAME) as session:\n",
    "    result = session.read_transaction( lambda tx: \n",
    "        tx.run(\n",
    "            \"\"\"\n",
    "            MATCH (i:Item{id: $itemid})<-[:VIEWED]-(visitor)-[bought:BOUGHT]->(otherItem)\n",
    "            WHERE i <> otherItem\n",
    "            AND NOT (:Visitor{id: $visitorid})-[:BOUGHT|ADDED]->(otherItem)\n",
    "            RETURN  otherItem.id as product_bought,\n",
    "                    otherItem.pagerank as rank,\n",
    "                    count(distinct bought) as times_bought\n",
    "            ORDER BY rank desc limit $limit\n",
    "            \"\"\",\n",
    "            limit = 10, itemid = 461686, visitorid=684514\n",
    "        ).data()\n",
    "    )\n",
    "    df = pd.DataFrame(result)\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate results\n",
    "Bloom, search for "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fa400fa1c59917a64ff3ea5ee959182f074bbc1e9a041e09cb658d2479256db7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
